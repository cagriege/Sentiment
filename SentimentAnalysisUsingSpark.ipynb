{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n",
    "from pyspark.sql import SparkSession\n",
    "#create Spark session\n",
    "appName = \"Sentiment Analysis in Spark\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(appName) \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---------------+---------------------------------+\n",
      "|ItemID|Sentiment|SentimentSource|SentimentText                    |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "|1038  |1        |Sentiment140   |that film is fantastic #brilliant|\n",
      "|1804  |1        |Sentiment140   |this music is really bad #myband |\n",
      "|1693  |0        |Sentiment140   |winter is terrible #thumbs-down  |\n",
      "+------+---------+---------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv file into dataFrame with automatically inferred schema\n",
    "tweets_csv = spark.read.csv('tweets.csv', inferSchema=True, header=True)\n",
    "tweets_csv.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|SentimentText                    |label|\n",
      "+---------------------------------+-----+\n",
      "|that film is fantastic #brilliant|1    |\n",
      "|this music is really bad #myband |1    |\n",
      "|winter is terrible #thumbs-down  |0    |\n",
      "|this game is awful #nightmare    |0    |\n",
      "|I love jam #loveit               |1    |\n",
      "+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#select only \"SentimentText\" and \"Sentiment\" column, \n",
    "#and cast \"Sentiment\" column data into integer\n",
    "data = tweets_csv.select(\"SentimentText\", col(\"Sentiment\").cast(\"Int\").alias(\"label\"))\n",
    "data.show(truncate = False,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 1348 ; Testing data rows: 584\n"
     ]
    }
   ],
   "source": [
    "#divide data, 70% for training, 30% for testing\n",
    "dividedData = data.randomSplit([0.7, 0.3]) \n",
    "trainingData = dividedData[0] #index 0 = data training\n",
    "testingData = dividedData[1] #index 1 = data testing\n",
    "train_rows = trainingData.count()\n",
    "test_rows = testingData.count()\n",
    "print (\"Training data rows:\", train_rows, \"; Testing data rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+---------------------------------------+\n",
      "|SentimentText                    |label|SentimentWords                         |\n",
      "+---------------------------------+-----+---------------------------------------+\n",
      "|I adore cheese #brilliant        |1    |[ı, adore, cheese, #brilliant]         |\n",
      "|I adore cheese #favorite         |1    |[ı, adore, cheese, #favorite]          |\n",
      "|I adore cheese #loveit           |1    |[ı, adore, cheese, #loveit]            |\n",
      "|I adore classical music #bestever|1    |[ı, adore, classical, music, #bestever]|\n",
      "|I adore classical music #loveit  |1    |[ı, adore, classical, music, #loveit]  |\n",
      "+---------------------------------+-----+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"SentimentText\", outputCol=\"SentimentWords\")\n",
    "tokenizedTrain = tokenizer.transform(trainingData)\n",
    "tokenizedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+---------------------------------------+---------------------------------------+\n",
      "|SentimentText                    |label|SentimentWords                         |MeaningfulWords                        |\n",
      "+---------------------------------+-----+---------------------------------------+---------------------------------------+\n",
      "|I adore cheese #brilliant        |1    |[ı, adore, cheese, #brilliant]         |[ı, adore, cheese, #brilliant]         |\n",
      "|I adore cheese #favorite         |1    |[ı, adore, cheese, #favorite]          |[ı, adore, cheese, #favorite]          |\n",
      "|I adore cheese #loveit           |1    |[ı, adore, cheese, #loveit]            |[ı, adore, cheese, #loveit]            |\n",
      "|I adore classical music #bestever|1    |[ı, adore, classical, music, #bestever]|[ı, adore, classical, music, #bestever]|\n",
      "|I adore classical music #loveit  |1    |[ı, adore, classical, music, #loveit]  |[ı, adore, classical, music, #loveit]  |\n",
      "+---------------------------------+-----+---------------------------------------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), \n",
    "                       outputCol=\"MeaningfulWords\")\n",
    "SwRemovedTrain = swr.transform(tokenizedTrain)\n",
    "SwRemovedTrain.show(truncate=False, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+------------------------------------------------------+\n",
      "|label|MeaningfulWords               |features                                              |\n",
      "+-----+------------------------------+------------------------------------------------------+\n",
      "|1    |[ı, adore, cheese, #brilliant]|(262144,[1689,45361,100089,231588],[1.0,1.0,1.0,1.0]) |\n",
      "|1    |[ı, adore, cheese, #favorite] |(262144,[1689,100089,108624,231588],[1.0,1.0,1.0,1.0])|\n",
      "|1    |[ı, adore, cheese, #loveit]   |(262144,[1689,100089,231588,254974],[1.0,1.0,1.0,1.0])|\n",
      "+-----+------------------------------+------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "numericTrainData = hashTF.transform(SwRemovedTrain).select(\n",
    "    'label', 'MeaningfulWords', 'features')\n",
    "numericTrainData.show(truncate=False, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", \n",
    "                        maxIter=10, regParam=0.01)\n",
    "model = lr.fit(numericTrainData)\n",
    "print (\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+-----------------------------------------------------+\n",
      "|Label|MeaningfulWords               |features                                             |\n",
      "+-----+------------------------------+-----------------------------------------------------+\n",
      "|1    |[ı, adore, cheese, #bestever] |(262144,[1689,91011,100089,231588],[1.0,1.0,1.0,1.0])|\n",
      "|1    |[ı, adore, cheese, #thumbs-up]|(262144,[1689,88825,100089,231588],[1.0,1.0,1.0,1.0])|\n",
      "+-----+------------------------------+-----------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedTest = tokenizer.transform(testingData)\n",
    "SwRemovedTest = swr.transform(tokenizedTest)\n",
    "numericTest = hashTF.transform(SwRemovedTest).select(\n",
    "    'Label', 'MeaningfulWords', 'features')\n",
    "numericTest.show(truncate=False, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+----------+-----+\n",
      "|MeaningfulWords                             |prediction|Label|\n",
      "+--------------------------------------------+----------+-----+\n",
      "|[ı, adore, cheese, #bestever]               |1.0       |1    |\n",
      "|[ı, adore, cheese, #thumbs-up]              |1.0       |1    |\n",
      "|[ı, adore, cheese, #toptastic]              |1.0       |1    |\n",
      "|[ı, adore, classical, music, #brilliant]    |1.0       |1    |\n",
      "|[ı, adore, classical, music, #favorite]     |1.0       |1    |\n",
      "|[ı, adore, classical, music, #thumbs-up]    |1.0       |1    |\n",
      "|[ı, adore, classical, music, #toptastic]    |1.0       |1    |\n",
      "|[ı, adore, coffee, #brilliant]              |1.0       |1    |\n",
      "|[ı, adore, coffee, #favorite]               |1.0       |1    |\n",
      "|[ı, adore, rock, music, #brilliant]         |1.0       |1    |\n",
      "|[ı, adore, skiing, #loveit]                 |1.0       |1    |\n",
      "|[ı, adore, summer, #favorite]               |1.0       |1    |\n",
      "|[ı, adore, summer, #toptastic]              |1.0       |1    |\n",
      "|[ı, adore, tea, #bestever]                  |1.0       |1    |\n",
      "|[ı, adore, tea, #brilliant]                 |1.0       |1    |\n",
      "|[ı, adore, tea, #toptastic]                 |1.0       |1    |\n",
      "|[ı, adore, band, #favorite]                 |1.0       |1    |\n",
      "|[ı, adore, band, #thumbs-up]                |1.0       |1    |\n",
      "|[ı, adore, film, #loveit]                   |1.0       |1    |\n",
      "|[ı, adore, film, #thumbs-up]                |1.0       |1    |\n",
      "|[ı, adore, film, #toptastic]                |1.0       |1    |\n",
      "|[ı, adore, movie, #bestever]                |1.0       |1    |\n",
      "|[ı, adore, holidays, #bestever]             |1.0       |1    |\n",
      "|[ı, adore, holidays, #favorite]             |1.0       |1    |\n",
      "|[ı, adore, holidays, #toptastic]            |1.0       |1    |\n",
      "|[ı, adore, band, #bestever]                 |1.0       |1    |\n",
      "|[ı, adore, band, #thumbs-up]                |1.0       |1    |\n",
      "|[ı, adore, book, #bestever]                 |1.0       |1    |\n",
      "|[ı, adore, book, #thumbs-up]                |1.0       |1    |\n",
      "|[ı, adore, book, #toptastic]                |1.0       |1    |\n",
      "|[ı, adore, game, #brilliant]                |1.0       |1    |\n",
      "|[ı, adore, winter, #bestever]               |1.0       |1    |\n",
      "|[ı, adore, winter, #loveit]                 |1.0       |1    |\n",
      "|[ı, adore, winter, #thumbs-up]              |1.0       |1    |\n",
      "|[ı, dislike, cheese, #fail]                 |0.0       |0    |\n",
      "|[ı, dislike, cheese, #rubbish]              |0.0       |0    |\n",
      "|[ı, dislike, cheese, #worstever]            |0.0       |0    |\n",
      "|[ı, dislike, classical, music, #fail]       |0.0       |0    |\n",
      "|[ı, dislike, classical, music, #thumbs-down]|0.0       |0    |\n",
      "|[ı, dislike, classical, music, #worstever]  |0.0       |0    |\n",
      "|[ı, dislike, coffee, #nightmare]            |0.0       |0    |\n",
      "|[ı, dislike, coffee, #thumbs-down]          |0.0       |0    |\n",
      "|[ı, dislike, jam, #hateit]                  |0.0       |0    |\n",
      "|[ı, dislike, jam, #worstever]               |0.0       |1    |\n",
      "|[ı, dislike, pop, music, #rubbish]          |0.0       |0    |\n",
      "|[ı, dislike, skiing, #hateit]               |0.0       |0    |\n",
      "|[ı, dislike, skiing, #thumbs-down]          |0.0       |0    |\n",
      "|[ı, dislike, summer, #worstever]            |0.0       |0    |\n",
      "|[ı, dislike, tea, #fail]                    |0.0       |0    |\n",
      "|[ı, dislike, tea, #hateit]                  |0.0       |0    |\n",
      "|[ı, dislike, band, #nightmare]              |0.0       |0    |\n",
      "|[ı, dislike, film, #hateit]                 |0.0       |0    |\n",
      "|[ı, dislike, film, #nightmare]              |0.0       |0    |\n",
      "|[ı, dislike, film, #rubbish]                |0.0       |0    |\n",
      "|[ı, dislike, movie, #worstever]             |0.0       |0    |\n",
      "|[ı, dislike, holidays, #thumbs-down]        |0.0       |0    |\n",
      "|[ı, dislike, band, #fail]                   |0.0       |0    |\n",
      "|[ı, dislike, band, #hateit]                 |0.0       |0    |\n",
      "|[ı, dislike, game, #worstever]              |0.0       |0    |\n",
      "|[ı, dislike, team, #fail]                   |0.0       |0    |\n",
      "|[ı, dislike, team, #nightmare]              |0.0       |0    |\n",
      "|[ı, dislike, team, #thumbs-down]            |0.0       |0    |\n",
      "|[ı, dislike, team, #worstever]              |0.0       |0    |\n",
      "|[ı, dislike, winter, #fail]                 |0.0       |0    |\n",
      "|[ı, dislike, winter, #hateit]               |0.0       |0    |\n",
      "|[ı, dislike, winter, #worstever]            |0.0       |0    |\n",
      "|[ı, hate, cheese, #worstever]               |0.0       |0    |\n",
      "|[ı, hate, classical, music, #hateit]        |0.0       |0    |\n",
      "|[ı, hate, classical, music, #nightmare]     |0.0       |0    |\n",
      "|[ı, hate, classical, music, #thumbs-down]   |0.0       |0    |\n",
      "|[ı, hate, classical, music, #worstever]     |0.0       |0    |\n",
      "|[ı, hate, coffee, #fail]                    |0.0       |0    |\n",
      "|[ı, hate, coffee, #hateit]                  |0.0       |0    |\n",
      "|[ı, hate, coffee, #thumbs-down]             |0.0       |0    |\n",
      "|[ı, hate, jam, #thumbs-down]                |0.0       |0    |\n",
      "|[ı, hate, jam, #worstever]                  |0.0       |0    |\n",
      "|[ı, hate, pop, music, #fail]                |0.0       |0    |\n",
      "|[ı, hate, rock, music, #nightmare]          |0.0       |0    |\n",
      "|[ı, hate, rock, music, #thumbs-down]        |0.0       |0    |\n",
      "|[ı, hate, skiing, #hateit]                  |0.0       |0    |\n",
      "|[ı, hate, skiing, #nightmare]               |0.0       |0    |\n",
      "|[ı, hate, skiing, #thumbs-down]             |0.0       |0    |\n",
      "|[ı, hate, summer, #nightmare]               |0.0       |0    |\n",
      "|[ı, hate, summer, #worstever]               |0.0       |0    |\n",
      "|[ı, hate, tea, #hateit]                     |0.0       |0    |\n",
      "|[ı, hate, tea, #thumbs-down]                |0.0       |0    |\n",
      "|[ı, hate, tea, #worstever]                  |0.0       |0    |\n",
      "|[ı, hate, band, #nightmare]                 |0.0       |0    |\n",
      "|[ı, hate, movie, #rubbish]                  |0.0       |0    |\n",
      "|[ı, hate, holidays, #nightmare]             |0.0       |0    |\n",
      "|[ı, hate, holidays, #thumbs-down]           |0.0       |0    |\n",
      "|[ı, hate, band, #rubbish]                   |0.0       |0    |\n",
      "|[ı, hate, book, #fail]                      |0.0       |0    |\n",
      "|[ı, hate, book, #worstever]                 |0.0       |0    |\n",
      "|[ı, hate, game, #nightmare]                 |0.0       |0    |\n",
      "|[ı, hate, game, #rubbish]                   |0.0       |0    |\n",
      "|[ı, hate, game, #worstever]                 |0.0       |0    |\n",
      "|[ı, hate, team, #fail]                      |0.0       |0    |\n",
      "|[ı, hate, team, #thumbs-down]               |0.0       |0    |\n",
      "|[ı, hate, winter, #hateit]                  |0.0       |0    |\n",
      "+--------------------------------------------+----------+-----+\n",
      "only showing top 100 rows\n",
      "\n",
      "correct prediction: 569 , total data: 584 , accuracy: 0.9743150684931506\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(numericTest)\n",
    "predictionFinal = prediction.select(\n",
    "    \"MeaningfulWords\", \"prediction\", \"Label\")\n",
    "predictionFinal.show(n=100, truncate = False)\n",
    "correctPrediction = predictionFinal.filter(\n",
    "    predictionFinal['prediction'] == predictionFinal['Label']).count()\n",
    "totalData = predictionFinal.count()\n",
    "print(\"correct prediction:\", correctPrediction, \", total data:\", totalData, \n",
    "      \", accuracy:\", correctPrediction/totalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
